{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "306ea2b3-bc60-4f25-8350-a56fa6e6bf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9e83c5e-b0cd-49e7-978a-a30a6b1343dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in ./myenv/lib/python3.8/site-packages (0.1.99)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece\n",
    "!pip install transformers\n",
    "import transformers\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f45303-1838-47fc-befa-67ce0a6c4f35",
   "metadata": {},
   "source": [
    "### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12f3ca57-7fc4-4f1a-b809-9dbccb326e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998711347579956},\n",
       " {'label': 'NEGATIVE', 'score': 0.9952723383903503}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "classifier([\"This coffee makes me happy\",\"Wow, the \\\n",
    "new office coffee blend tastes like shit\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ebdf36-bcb4-40a4-bb5b-51da3f470a7e",
   "metadata": {},
   "source": [
    "### Zero-Shot Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa7385bd-8f77-401d-999f-164b98d99c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision c626438 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': 'Dealing with a break up is tough. My cat had a break-up',\n",
       " 'labels': ['cat', 'break-up', 'read'],\n",
       " 'scores': [0.6578593254089355, 0.26527056097984314, 0.07687017321586609]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(\"zero-shot-classification\")\n",
    "classifier(\n",
    "    \"Dealing with a break up is tough. My cat had a break-up\",\n",
    "    candidate_labels=[\"read\", \"cat\", \"break-up\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ce8a0f-6ff2-43be-bdcf-5a0c41504754",
   "metadata": {},
   "source": [
    "### Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d979769-9c76-4c1d-b4b7-ada2832cb410",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"I want to become a transformer because it's all about the energy that's coming from it and creating power that's coming from what it's doing, and what it needs to be doing because I want to play a role that's so important and something\"},\n",
       " {'generated_text': 'I want to become a transformer because it is my dream.”'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = pipeline(\"text-generation\", model=\"distilgpt2\")\n",
    "generator(\n",
    "    \"I want to become a transformer because\",\n",
    "    max_length=50,\n",
    "    num_return_sequences=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e148cd-b1dc-422c-af84-1010d54dbf7c",
   "metadata": {},
   "source": [
    "### Mask Filling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a78f4f6-babf-471c-94e1-cbbd98315b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilroberta-base and revision ec58a5b (https://huggingface.co/distilroberta-base).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.03577457740902901,\n",
       "  'token': 16333,\n",
       "  'token_str': ' genius',\n",
       "  'sequence': 'Hey girl! You look like a genius.'},\n",
       " {'score': 0.03416949883103371,\n",
       "  'token': 38525,\n",
       "  'token_str': ' badass',\n",
       "  'sequence': 'Hey girl! You look like a badass.'},\n",
       " {'score': 0.019076498225331306,\n",
       "  'token': 35545,\n",
       "  'token_str': ' unicorn',\n",
       "  'sequence': 'Hey girl! You look like a unicorn.'},\n",
       " {'score': 0.0176495760679245,\n",
       "  'token': 19169,\n",
       "  'token_str': ' princess',\n",
       "  'sequence': 'Hey girl! You look like a princess.'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker = pipeline(\"fill-mask\")\n",
    "unmasker(\"Hey girl! You look like a <mask> .\", top_k=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26314b93-adaf-49d8-a343-2c57a7f75178",
   "metadata": {},
   "source": [
    "### Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e93828ea-2abe-4586-a99c-b0b40ff7c00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'PER',\n",
       "  'score': 0.98933816,\n",
       "  'word': 'Popo',\n",
       "  'start': 40,\n",
       "  'end': 44},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.8485607,\n",
       "  'word': 'Google Headquarters',\n",
       "  'start': 61,\n",
       "  'end': 80},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.9979704,\n",
       "  'word': 'Mars',\n",
       "  'start': 152,\n",
       "  'end': 156}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner = pipeline(\"ner\", grouped_entities=True)\n",
    "ner(\"The chocolate thief was none other than Popo who stole it at Google Headquarters because he was too excited after reading my story. He was last seen on Mars.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455c862e-0f94-40b5-9c71-7a29eb5e0816",
   "metadata": {},
   "source": [
    "### Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3c7a79e5-d00b-4a5c-b354-9de7279213ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.21733985841274261, 'start': 10, 'end': 13, 'answer': 'dog'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_answerer = pipeline(\"question-answering\")\n",
    "question_answerer(\n",
    "    question=\"Who am I?\",\n",
    "    context=\"I lost my dog and I lost myself. Then I found my dog and I found myself.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e4794990-c128-4668-9da1-30aa1ac86a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.6490179896354675, 'start': 81, 'end': 86, 'answer': 'games'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_answerer = pipeline(\"question-answering\")\n",
    "question_answerer(\n",
    "    question=\"What does the dog want?\",\n",
    "    context=\"I lost my dog and I lost myself. Then I found my dog and I found myself. You got games on yo phone\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e57a96-b430-4387-a6a3-b43ce1e8c229",
   "metadata": {},
   "source": [
    "### Text Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "794b9170-4303-487f-a2f7-7f5e99f4b233",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': \" It's the thrill of a silent movie but without the old-timey charm,\"}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer = pipeline('summarization')\n",
    "summarizer('''Hope this message finds you in the land of decipherable texts.\n",
    "\n",
    "Remember the date night that didn't quite register on your radar? I had my sparkly socks on and everything. It was like a disappearing act — my presence vanished into thin air. Is there an invisibility cloak involved that I'm not aware of?\n",
    "\n",
    "Then, there's the text marathon. I'm unleashing paragraphs, and I'm met with one-word replies. Are we playing a word-limit game? Because if so, you're absolutely acing it. I might need a decoder ring to get the deeper meaning.\n",
    "\n",
    "And let's not forget the thrill of our conversations. I'm sharing tales, and it feels like I'm narrating to a tumbleweed rolling by. It's the thrill of a silent movie but without the old-timey charm. Am I missing a script?\n",
    "\n",
    "So, here's the thing — I'm lost in translation. If there's a secret language or a manual hidden somewhere, kindly point me in that direction. If not, let's figure this out together, preferably without Morse code.\n",
    "\n",
    "Hope to unravel the mystery soon. Anyway. I'm doing my detective work, folding clothes like a pro, and bam — the socks have staged a vanishing act. Where do they go? Is there a sock black hole in the laundry machine? Do they elope with the missing Tupperware lids? I have questions.\n",
    "\n",
    "And don't get me started on the fridge. It's like a culinary treasure hunt in there. I open it, expecting some leftovers, and voilà, it's an adventure. Mystery containers, unidentified substances — it's like a puzzle waiting to be solved.\n",
    "\n",
    "Speaking of puzzles, let's circle back to our conversations. It feels like we're playing a game of Scrabble with life events. I'm tossing out words, and it's your turn. Bonus points if you can form a sentence. Just kidding, but seriously, let's break the code.''', min_length=10, max_length=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b2dbac-62cc-4e52-9672-fbbf99235c4a",
   "metadata": {},
   "source": [
    "### Language Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51e49940-a38d-40fb-8177-0375ccfb26d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'My grandmother plays better than you.'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-ru-en\")\n",
    "translator(\"моя бабушка играет лучше тебя\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
